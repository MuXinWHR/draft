
###目标

* 高可用
* 容错

###假设

多台服务器提供同一服务, 多个客户端访问该服务.

* 每个服务端以接收请求消息的顺序执行请求. 并按照接受请求消息的顺序应答.
* 每个服务端每处理一个客户端的请求, 进行一次状态改变.
* 同一客户端的请求必须按照顺序执行, 并且在所有服务器看来顺序都是一致的.
* 不同客户端的请求是不相关的, 它们之间的顺序没有任何关系.

* 网络是不可靠的, 随时会出现问题.
* 服务器是不可靠的, 随时会宕机


##情况1

两台服务器都提供相同的服务, 但是, 它们之间不进行任何同步.

![图1](paxos_1.png)

反例: C1 发送请求给 S1, S2, C2 发送请求给 S1, S2. 完成可能出现的情况是:

* S1 首先接收到 C1 的请求, 之后接收到 C2 的请求;
* S2 首先接收到 C2 的请求, 之后接收到 C1 的请求;

很明显, S1, S2 的状态不一致了. 如上图.

##情况2

两台服务器都提供相同的服务, 它们一主一从(Master-Slave). 每次 Master 服务器
收到请求, 就将 <acc, mi, j> 请求发送给 Slave 服务器, 之后在本地执行该请求.

其中 <acc,mi, j> 中, j 为第 j 个请求为 mi.

![图2](paxos_2.png)

Master 首先接收到 C1 的请求, 发送 <acc, m1, 1>　给 Slave 之后, 在本地处理 C1
的请求; 之后接收到 C2 的请求, 发送 <acc, m2, 2> 给 Slave 之后, 在本地处理 C2,
的请求;

Slave 接收到 <acc, m1, 1> 消息, 在本地执行; 接收到 <acc, m2, 2> 消息, 在本地
执行

###问题1

如果 Slave 没有收到 <acc, m1, 1> 消息, 即使收到 <acc, m2, 2> 消息也不会
执行 m2 消息. 而由于网络异常, 丢失 <acc, m1, 1> 完全是可能的. 如果前面的消息
丢失, 那么, 后面的请求都被阻塞. 见图 2

解决办法: Master 要求 Slave 应答收到的消息, 如果超时没有收到 Slave 的确认. 就
重传. 见图3

![图3](paxos_3.png)

可见, 在此种情况下, 可以保证一致性.

###问题2

如果 Master 服务器宕机后, 显然 Slave 收不到 Master 的消息, 就一直阻塞.

解决办法: 通过外部程序监控 Master, Slave, 在 Master 宕机后, 将 Slave 变为主.
但这引入一个新问题, 脑裂(问题5).

###问题3

即使问题2 得到解决, 也仍然存在问题:

首先对于一个请求, 存在如下过程(以 C1 为例):

####Master

1) C1 发送请求
2) Master 接收 C1 请求
3) Master 发送 <acc, m1, 1> 给 Slave
4) Master 在本地执行请求(假设这个操作是成功或失败, 没有中间状态)
5) Master 应答 C1
6) C1 接收到应答
4,5,6) Master 接收 Slave

####Slave

1) Slave 接收 Master 的 <acc, m1, 1> 消息
2) Slave 执行消息对应的操作(假设这个操作是成功或失败, 没有中间状态)
3) Slave 确认 Master 消息

Master 宕机在以上任何一个阶段都可能发生!

Master 接受 C1 请求, Master 发送 (acc, m1, 1) 给 Slave 服务器, 应答 C1. 而
(acc, m1, 1) 恰好丢失了, 在重传之前, 就宕机了. 这时, Slave 服务器接变为 Master.
C1 继续后续请求在之前 Slave, 但 C1 之前的操作实际在 Slave 没有执行. 导致数据不
一致. 见图4

![图4](paxos_4.png)

解决办法是, Master 在收到 Slave 的应答之后, 在应答 C1

###问题 4

通过调整顺序为:

####Master

1. C1 发送请求
2. Master 接收 C1 请求
3. Master 发送 <acc, m1, 1> 给 Slave
4. Master 接收 Slave
5. Master 在本地执行请求(假设这个操作是成功或失败, 没有中间状态)
6. Master 应答 C1
7. C1 接收到应答

####Slave

1. Slave 接收 Master 的 <acc, m1, 1> 消息
2. Slave 执行消息对应的操作(假设这个操作是成功或失败, 没有中间状态)
3. Slave 确认 Master 消息

如果 Master 在本地执行完成, 宕机了. 结果没有应答 C1 请求.


![图5](paxos_5.png)

###问题5

如果 Master 和 Slave 都没有宕机, 但是它们之间的网络不通了, 那么, 很
显然, Master 和 Slave 都认为自己是 Master,其中的问题是显而易见的.

![图6](paxos_6.png)

解决办法:
1. 网卡 bond, 可以解决网卡问题. 但无法解决网络问题.
2. 引入新的节点. 这样, 三台机器中有任意两台机器直接出现网络问题, 或者
其中一台机器宕机. 见图 7

![图7](paxos_7.png)

###问题6

当引入第三台服务器的时候, 有一个明显的问题需要考虑, 即, 是否所有服务器
都可以接受写请求. 如果可以, 那么, 现在假设, S1, S2 都接受到写请求 C1,C2.
, S1 先接收到请求的顺序是 C1, C2, 因此, S1 发送 <acc, m1, 1>, <acc, m2,2>
S2 发送 <acc, m2, 1>. <acc, m1, 1>. S1, S2 的状态已经不一致了.

![图8](paxos_8.png)

解决办法: 只有一个 Master, 其他服务器都是 Slave. Master 在每次操作之前
都发送一个 Prep 消息, 当多余一半的 Slave 确认时, 继续发送 accept 消息.
由于引入leader, 为了让 Slave 识别是哪个 master 发送的消息(尤其是在旧
leader 宕机, 新 leader 刚刚选举出来). 每个消息都加入 master Id

* accept
* learn
* prepare
* promise

###问题7

合并分区(Merge partitions), 每个 leader 都有一个排名. 出现多个 leader 之后
排名更高的 leader 成为真正的 leader

![图10](paxos_10.png)

(Round Numbers) 排名的机制存在问题, 因此引入, Round Numbers. 而这些 Round
Numbers 一般都是预先分配好. 比如 S1 1,4,7 S2 2,5,8

为了更好的冗余, 在发生网络分区的时候, 让主要分区(多余 1 半的服务器)能够继续
服务, 即允许少于 1/2 服务器发生故障. 在 5 台提供了更好的冗余性. leader 在
收到两个 learn 可以继续. follower 收到一个 accept 和一个 learn 可以继续.
因此, 一个新的 leader 需要收到两个 promise, 才让自己变为 leader 角色.




附录:

Paxos 要求消息顺序在每台服务器的一致性, 而我们有时候并不需要这种消息顺序
的一致性. 而只要保证对同一个值的修改.
